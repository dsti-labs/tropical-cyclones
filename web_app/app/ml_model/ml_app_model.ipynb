{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Machine Learning Model \n",
    "\n",
    "\n",
    "obenob\n",
    "new data new model \n",
    "\n",
    "\n",
    "## Imports \n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import pprint\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    OrdinalEncoder, \n",
    "    OneHotEncoder\n",
    ")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import (\n",
    "    r2_score, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    make_scorer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_parquet(\"../../../data/df_app.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_init.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45025 entries, 0 to 67409\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SID           45025 non-null  object \n",
      " 1   SEASON        45025 non-null  object \n",
      " 2   BASIN         45025 non-null  object \n",
      " 3   NATURE        45025 non-null  object \n",
      " 4   LAT           45025 non-null  float64\n",
      " 5   LON           45025 non-null  float64\n",
      " 6   WIND          45025 non-null  float64\n",
      " 7   DIST2LAND     45025 non-null  int64  \n",
      " 8   STORM_SPEED   45025 non-null  float64\n",
      " 9   STORM_DIR     45025 non-null  float64\n",
      " 10  TD9636_STAGE  45025 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate the data that will be given to the machine learning model to train and test from the data that will be used in the application so that it is \"new data never seen before\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop some rows so that the model is not test/trained on them and so that they are not inserted into the small database in the app from the get-go. We are dropping :\n",
    "\n",
    "- a random cyclone of stage 0 (so that the model never trained on any data from that cyclone)\n",
    "- a random row from a random cyclone of stage 4\n",
    "- a random row from a random cyclone of stage 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 0\n",
    "stage_0_cyclones = df[df['TD9636_STAGE'] == 0]\n",
    "random_cyclone_id_0 = np.random.choice(stage_0_cyclones['SID'].unique())\n",
    "\n",
    "# store dropped rows\n",
    "dropped_df = df[df[\"SID\"] == random_cyclone_id_0]\n",
    "# immediately drop the cyclone from the dataset so that the next randoms don't come from the same cyclone\n",
    "df = df[df[\"SID\"] != random_cyclone_id_0]\n",
    "\n",
    "# stage 4\n",
    "stage_4_cyclones = df[df['TD9636_STAGE'] == 4]\n",
    "random_row_4 = stage_4_cyclones.sample(n=1).index.item()\n",
    "\n",
    "dropped_df = pd.concat([dropped_df,  df[df.index == random_row_4]])\n",
    "df = df.drop(index=random_row_4)\n",
    "\n",
    "# stage 5\n",
    "stage_5_cyclones = df[df['TD9636_STAGE'] == 5]\n",
    "random_row_5 = stage_5_cyclones.sample(n=1).index.item()\n",
    "\n",
    "dropped_df = pd.concat([dropped_df,  df[df.index == random_row_5]])\n",
    "df = df.drop(index=random_row_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SID             0\n",
       "SEASON          0\n",
       "BASIN           0\n",
       "NATURE          0\n",
       "LAT             0\n",
       "LON             0\n",
       "WIND            0\n",
       "DIST2LAND       0\n",
       "STORM_SPEED     0\n",
       "STORM_DIR       0\n",
       "TD9636_STAGE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>WIND</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "      <th>TD9636_STAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>14.4</td>\n",
       "      <td>125.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "      <td>17.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>14.8</td>\n",
       "      <td>124.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90</td>\n",
       "      <td>16.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.2</td>\n",
       "      <td>123.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>134</td>\n",
       "      <td>14.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>123</td>\n",
       "      <td>11.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.7</td>\n",
       "      <td>122.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>TS</td>\n",
       "      <td>15.8</td>\n",
       "      <td>122.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39</td>\n",
       "      <td>9.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60966</th>\n",
       "      <td>1989052S27233</td>\n",
       "      <td>summer</td>\n",
       "      <td>SP</td>\n",
       "      <td>TS</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>-141.4</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>6.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>1980208N23153</td>\n",
       "      <td>summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>TS</td>\n",
       "      <td>36.5</td>\n",
       "      <td>155.8</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1132</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SID  SEASON BASIN NATURE   LAT    LON  WIND  DIST2LAND  \\\n",
       "3432   1980225N11145  summer    WP     MX  14.4  125.1  20.0         94   \n",
       "3433   1980225N11145  summer    WP     MX  14.8  124.4  20.0         90   \n",
       "3434   1980225N11145  summer    WP     MX  15.2  123.6  20.0        134   \n",
       "3435   1980225N11145  summer    WP     MX  15.4  123.0  18.0        123   \n",
       "3436   1980225N11145  summer    WP     MX  15.7  122.6  15.0         69   \n",
       "3437   1980225N11145  summer    WP     TS  15.8  122.3  28.0         39   \n",
       "60966  1989052S27233  summer    SP     TS -32.2 -141.4  63.0       3660   \n",
       "3047   1980208N23153  summer    WP     TS  36.5  155.8  44.8       1132   \n",
       "\n",
       "       STORM_SPEED  STORM_DIR  TD9636_STAGE  \n",
       "3432          17.0      295.0           0.0  \n",
       "3433          16.0      295.0           0.0  \n",
       "3434          14.0      295.0           1.0  \n",
       "3435          11.0      295.0           1.0  \n",
       "3436           8.0      300.0           6.0  \n",
       "3437           9.0      300.0           6.0  \n",
       "60966          6.0      135.0           4.0  \n",
       "3047          14.0       25.0           5.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>WIND</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "      <th>TD9636_STAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SID, SEASON, BASIN, NATURE, LAT, LON, WIND, DIST2LAND, STORM_SPEED, STORM_DIR, TD9636_STAGE]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"SID\"] == \"1980225N11145\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/dataframe/dataframe.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Encoding Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Columns\n",
    "\n",
    "1. Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEASON is encoded using OrdinalEncoder() from Scikit-learn. OrdinalEncoder() assigns a unique integer to each category in a feature, creating an ordinal relationship between the categories, giving more weight to seasons with more frequent and stronger storms (Winter < Spring < Fall < Summer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Basin & Nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NATURE AND BASIN columns are encoded with the OneHotEncoder() class from the pandas library. This is a function used for one-hot encoding of categorical variables. It converts categorical data into dummy or indicator variables, creating new columns for each unique category with binary values (0 or 1) to indicate the presence or absence of that category in each row.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Storm direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORM_DIR represents a direction expressed in degrees; hence the variable was scaled by extracting the X and Y vectors of the direction using numpyâ€™s cosinus and sinus methods. As this preprocessing is personalized it needs to be defined in the new class StormDirTransformer(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StormDirTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col=\"STORM_DIR\"):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nothing to fit\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = np.cos(np.radians(X[self.col]))\n",
    "        y = np.sin(np.radians(X[self.col]))\n",
    "        return np.c_[x, y]  # Returns a 2D array\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"x\", f\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(dataset_name, model, model_name):\n",
    "    # Save the best model\n",
    "    joblib.dump(model, f\"../data/weights/{dataset_name}_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(dataframe: pd.DataFrame, classifier, preprocessor, balance: bool = False, cv_folds: int = 5):\n",
    "    # Define features and target\n",
    "    target = dataframe[\"TD9636_STAGE\"]\n",
    "    features = dataframe.drop(columns=['TD9636_STAGE'])\n",
    "\n",
    "    print(\"Running through the pipeline with cross-validation\")\n",
    "\n",
    "    # Use StratifiedKFold for better class distribution in folds\n",
    "    #  KFold, RepeatedStratifiedKFold, StratifiedKFold\n",
    "    # cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=cv_folds, random_state=42)\n",
    "    \n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        \"accuracy\": make_scorer(accuracy_score),\n",
    "        \"precision\": make_scorer(precision_score, average=\"weighted\"),\n",
    "        \"recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "        \"f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "        \"r2_score\": make_scorer(r2_score),\n",
    "    }\n",
    "\n",
    "    if balance:\n",
    "        print(\"Using SMOTE for balancing\")\n",
    "        pipe = ImbPipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    \n",
    "    cv_results = cross_validate(pipe, features, target, cv=cv, scoring=scoring, return_estimator=True)\n",
    "\n",
    "    # Calculate mean scores\n",
    "    scores = {metric: round(cv_results[f\"test_{metric}\"].mean(), 4) for metric in scoring}\n",
    "\n",
    "    # Print results\n",
    "    print(\"---- CROSS-VALIDATION RESULTS ----\")\n",
    "    pprint.pprint(scores)\n",
    "\n",
    "    return cv_results, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", OrdinalEncoder(categories=[['winter', 'spring', 'fall', 'summer']]), [\"SEASON\"]),\n",
    "        (\"storm_dir_transform\", StormDirTransformer(), [\"STORM_DIR\"]),\n",
    "        (\"num\", StandardScaler(), [\"WIND\", \"DIST2LAND\", \"STORM_SPEED\"]),  \n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), [\"BASIN\", \"NATURE\"])  \n",
    "    ],  \n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model established with gridSearch for balanced (augmented) dataset \n",
    "estimator = HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.2,max_bins=128, max_iter=500, random_state=42)\n",
    "\n",
    "# estimator = KNeighborsClassifier(n_neighbors=2)\n",
    "# estimator = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the SID column to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"SID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through the pipeline with cross-validation\n",
      "Using SMOTE for balancing\n",
      "---- CROSS-VALIDATION RESULTS ----\n",
      "{'accuracy': np.float64(0.9275),\n",
      " 'f1': np.float64(0.9274),\n",
      " 'precision': np.float64(0.9276),\n",
      " 'r2_score': np.float64(0.8859),\n",
      " 'recall': np.float64(0.9275)}\n"
     ]
    }
   ],
   "source": [
    "cv_results, scores = model_pipeline(df, estimator, preprocessor, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the best model based on accuracy (or another metric)\n",
    "best_index = np.argmax(cv_results[\"test_accuracy\"])  # Using accuracy as the criterion\n",
    "# Retrieve the best model\n",
    "best_model = cv_results[\"estimator\"][best_index]\n",
    "\n",
    "save_model_weights(\"base_augmented\", best_model, \"histGradientBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tropical_cyclones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
