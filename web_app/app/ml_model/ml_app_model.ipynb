{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Machine Learning Model \n",
    "\n",
    "\n",
    "obenob\n",
    "new data new model \n",
    "\n",
    "\n",
    "## Imports \n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import pprint\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    OrdinalEncoder, \n",
    "    OneHotEncoder\n",
    ")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import (\n",
    "    r2_score, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    make_scorer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_parquet(\"../../../data/df_app.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_init.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45025 entries, 0 to 67409\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   SID           45025 non-null  object        \n",
      " 1   ISO_TIME      45025 non-null  datetime64[ns]\n",
      " 2   SEASON        45025 non-null  object        \n",
      " 3   BASIN         45025 non-null  object        \n",
      " 4   NATURE        45025 non-null  object        \n",
      " 5   LAT           45025 non-null  float64       \n",
      " 6   LON           45025 non-null  float64       \n",
      " 7   WIND          45025 non-null  float64       \n",
      " 8   DIST2LAND     45025 non-null  int64         \n",
      " 9   STORM_SPEED   45025 non-null  float64       \n",
      " 10  STORM_DIR     45025 non-null  float64       \n",
      " 11  TD9636_STAGE  45025 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(4)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate the data that will be given to the machine learning model to train and test from the data that will be used in the application so that it is \"new data never seen before\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop some rows so that the model is not test/trained on them and so that they are not inserted into the small database in the app from the get-go. We are dropping :\n",
    "\n",
    "- a random cyclone of stage 0 (so that the model never trained on any data from that cyclone)\n",
    "- a random row from a random cyclone of stage 4\n",
    "- a random row from a random cyclone of stage 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 0\n",
    "stage_0_cyclones = df[df['TD9636_STAGE'] == 0]\n",
    "random_cyclone_id_0 = np.random.choice(stage_0_cyclones['SID'].unique())\n",
    "\n",
    "# store dropped rows\n",
    "dropped_df = df[df[\"SID\"] == random_cyclone_id_0]\n",
    "# immediately drop the cyclone from the dataset so that the next randoms don't come from the same cyclone\n",
    "df = df[df[\"SID\"] != random_cyclone_id_0]\n",
    "\n",
    "# stage 4\n",
    "stage_4_cyclones = df[df['TD9636_STAGE'] == 4]\n",
    "random_row_4 = stage_4_cyclones.sample(n=1).index.item()\n",
    "\n",
    "dropped_df = pd.concat([dropped_df,  df[df.index == random_row_4]])\n",
    "df = df.drop(index=random_row_4)\n",
    "\n",
    "# stage 5\n",
    "stage_5_cyclones = df[df['TD9636_STAGE'] == 5]\n",
    "random_row_5 = stage_5_cyclones.sample(n=1).index.item()\n",
    "\n",
    "dropped_df = pd.concat([dropped_df,  df[df.index == random_row_5]])\n",
    "df = df.drop(index=random_row_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SID             0\n",
       "ISO_TIME        0\n",
       "SEASON          0\n",
       "BASIN           0\n",
       "NATURE          0\n",
       "LAT             0\n",
       "LON             0\n",
       "WIND            0\n",
       "DIST2LAND       0\n",
       "STORM_SPEED     0\n",
       "STORM_DIR       0\n",
       "TD9636_STAGE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>WIND</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "      <th>TD9636_STAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-11 12:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>6.9</td>\n",
       "      <td>148.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1015</td>\n",
       "      <td>6.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-11 15:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>6.9</td>\n",
       "      <td>148.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1012</td>\n",
       "      <td>6.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-11 18:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>6.9</td>\n",
       "      <td>147.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-11 21:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>7.0</td>\n",
       "      <td>147.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-12 00:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>7.0</td>\n",
       "      <td>147.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1019</td>\n",
       "      <td>6.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-21 15:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>TS</td>\n",
       "      <td>35.2</td>\n",
       "      <td>142.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>189</td>\n",
       "      <td>33.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-21 18:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>36.4</td>\n",
       "      <td>144.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>292</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>1980133N07149</td>\n",
       "      <td>1980-05-21 21:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>37.1</td>\n",
       "      <td>145.3</td>\n",
       "      <td>72.8</td>\n",
       "      <td>359</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59294</th>\n",
       "      <td>1988310S08100</td>\n",
       "      <td>1988-11-13 06:00:00</td>\n",
       "      <td>Spring</td>\n",
       "      <td>SI</td>\n",
       "      <td>TS</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>84.7</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1687</td>\n",
       "      <td>9.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61919</th>\n",
       "      <td>1989106S11128</td>\n",
       "      <td>1989-04-24 12:00:00</td>\n",
       "      <td>Fall</td>\n",
       "      <td>SI</td>\n",
       "      <td>ET</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>130.2</td>\n",
       "      <td>22.4</td>\n",
       "      <td>44</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SID            ISO_TIME  SEASON BASIN NATURE   LAT    LON  \\\n",
       "2014   1980133N07149 1980-05-11 12:00:00  Spring    WP     MX   6.9  148.5   \n",
       "2015   1980133N07149 1980-05-11 15:00:00  Spring    WP     MX   6.9  148.2   \n",
       "2016   1980133N07149 1980-05-11 18:00:00  Spring    WP     MX   6.9  147.9   \n",
       "2017   1980133N07149 1980-05-11 21:00:00  Spring    WP     MX   7.0  147.7   \n",
       "2018   1980133N07149 1980-05-12 00:00:00  Spring    WP     MX   7.0  147.4   \n",
       "...              ...                 ...     ...   ...    ...   ...    ...   \n",
       "2095   1980133N07149 1980-05-21 15:00:00  Spring    WP     TS  35.2  142.9   \n",
       "2096   1980133N07149 1980-05-21 18:00:00  Spring    WP     MX  36.4  144.2   \n",
       "2097   1980133N07149 1980-05-21 21:00:00  Spring    WP     MX  37.1  145.3   \n",
       "59294  1988310S08100 1988-11-13 06:00:00  Spring    SI     TS  -8.6   84.7   \n",
       "61919  1989106S11128 1989-04-24 12:00:00    Fall    SI     ET -32.0  130.2   \n",
       "\n",
       "       WIND  DIST2LAND  STORM_SPEED  STORM_DIR  TD9636_STAGE  \n",
       "2014   15.0       1015          6.0      270.0           0.0  \n",
       "2015   15.0       1012          6.0      270.0           0.0  \n",
       "2016   15.0       1010          5.0      275.0           0.0  \n",
       "2017   18.0       1020          5.0      280.0           0.0  \n",
       "2018   20.0       1019          6.0      275.0           0.0  \n",
       "...     ...        ...          ...        ...           ...  \n",
       "2095   33.0        189         33.0       45.0           2.0  \n",
       "2096   30.0        292         26.0       45.0           5.0  \n",
       "2097   72.8        359         26.0       45.0           5.0  \n",
       "59294  65.0       1687          9.0      230.0           4.0  \n",
       "61919  22.4         44         33.0      105.0           5.0  \n",
       "\n",
       "[86 rows x 12 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>WIND</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "      <th>TD9636_STAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-14 18:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>14.4</td>\n",
       "      <td>125.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "      <td>17.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-14 21:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>14.8</td>\n",
       "      <td>124.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90</td>\n",
       "      <td>16.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-15 00:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.2</td>\n",
       "      <td>123.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>134</td>\n",
       "      <td>14.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-15 03:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>123</td>\n",
       "      <td>11.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-15 06:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>MX</td>\n",
       "      <td>15.7</td>\n",
       "      <td>122.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>1980225N11145</td>\n",
       "      <td>1980-08-15 09:00:00</td>\n",
       "      <td>Summer</td>\n",
       "      <td>WP</td>\n",
       "      <td>TS</td>\n",
       "      <td>15.8</td>\n",
       "      <td>122.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39</td>\n",
       "      <td>9.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SID            ISO_TIME  SEASON BASIN NATURE   LAT    LON  \\\n",
       "3432  1980225N11145 1980-08-14 18:00:00  Summer    WP     MX  14.4  125.1   \n",
       "3433  1980225N11145 1980-08-14 21:00:00  Summer    WP     MX  14.8  124.4   \n",
       "3434  1980225N11145 1980-08-15 00:00:00  Summer    WP     MX  15.2  123.6   \n",
       "3435  1980225N11145 1980-08-15 03:00:00  Summer    WP     MX  15.4  123.0   \n",
       "3436  1980225N11145 1980-08-15 06:00:00  Summer    WP     MX  15.7  122.6   \n",
       "3437  1980225N11145 1980-08-15 09:00:00  Summer    WP     TS  15.8  122.3   \n",
       "\n",
       "      WIND  DIST2LAND  STORM_SPEED  STORM_DIR  TD9636_STAGE  \n",
       "3432  20.0         94         17.0      295.0           0.0  \n",
       "3433  20.0         90         16.0      295.0           0.0  \n",
       "3434  20.0        134         14.0      295.0           1.0  \n",
       "3435  18.0        123         11.0      295.0           1.0  \n",
       "3436  15.0         69          8.0      300.0           6.0  \n",
       "3437  28.0         39          9.0      300.0           6.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"SID\"] == \"1980225N11145\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/dataframe/dataframe.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Encoding Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Columns\n",
    "\n",
    "1. Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEASON is encoded using OrdinalEncoder() from Scikit-learn. OrdinalEncoder() assigns a unique integer to each category in a feature, creating an ordinal relationship between the categories, giving more weight to seasons with more frequent and stronger storms (Winter < Spring < Fall < Summer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Basin & Nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NATURE AND BASIN columns are encoded with the OneHotEncoder() class from the pandas library. This is a function used for one-hot encoding of categorical variables. It converts categorical data into dummy or indicator variables, creating new columns for each unique category with binary values (0 or 1) to indicate the presence or absence of that category in each row.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Storm direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORM_DIR represents a direction expressed in degrees; hence the variable was scaled by extracting the X and Y vectors of the direction using numpy’s cosinus and sinus methods. As this preprocessing is personalized it needs to be defined in the new class StormDirTransformer(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StormDirTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col=\"STORM_DIR\"):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nothing to fit\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = np.cos(np.radians(X[self.col]))\n",
    "        y = np.sin(np.radians(X[self.col]))\n",
    "        return np.c_[x, y]  # Returns a 2D array\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"x\", f\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(dataset_name, model, model_name):\n",
    "    # Save the best model\n",
    "    joblib.dump(model, f\"../data/weights/{dataset_name}_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(dataframe: pd.DataFrame, classifier, preprocessor, balance: bool = False, cv_folds: int = 5):\n",
    "    # Define features and target\n",
    "    target = dataframe[\"TD9636_STAGE\"]\n",
    "    features = dataframe.drop(columns=['TD9636_STAGE'])\n",
    "\n",
    "    print(\"Running through the pipeline with cross-validation\")\n",
    "\n",
    "    # Use StratifiedKFold for better class distribution in folds\n",
    "    #  KFold, RepeatedStratifiedKFold, StratifiedKFold\n",
    "    # cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=cv_folds, random_state=42)\n",
    "    \n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        \"accuracy\": make_scorer(accuracy_score),\n",
    "        \"precision\": make_scorer(precision_score, average=\"weighted\"),\n",
    "        \"recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "        \"f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "        \"r2_score\": make_scorer(r2_score),\n",
    "    }\n",
    "\n",
    "    if balance:\n",
    "        print(\"Using SMOTE for balancing\")\n",
    "        pipe = ImbPipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    \n",
    "    cv_results = cross_validate(pipe, features, target, cv=cv, scoring=scoring, return_estimator=True)\n",
    "\n",
    "    # Calculate mean scores\n",
    "    scores = {metric: round(cv_results[f\"test_{metric}\"].mean(), 4) for metric in scoring}\n",
    "\n",
    "    # Print results\n",
    "    print(\"---- CROSS-VALIDATION RESULTS ----\")\n",
    "    pprint.pprint(scores)\n",
    "\n",
    "    return cv_results, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", OrdinalEncoder(categories=[['Winter', 'Spring', 'Fall', 'Summer']]), [\"SEASON\"]),\n",
    "        (\"storm_dir_transform\", StormDirTransformer(), [\"STORM_DIR\"]),\n",
    "        (\"num\", StandardScaler(), [\"WIND\", \"DIST2LAND\", \"STORM_SPEED\"]),  \n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), [\"BASIN\", \"NATURE\"])  \n",
    "    ],  \n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model established with gridSearch for balanced (augmented) dataset \n",
    "estimator = HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.2,max_bins=128, max_iter=500, random_state=42)\n",
    "\n",
    "# estimator = KNeighborsClassifier(n_neighbors=2)\n",
    "# estimator = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the SID column to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"SID\"], inplace=True)\n",
    "df.drop(columns=[\"ISO_TIME\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through the pipeline with cross-validation\n",
      "Using SMOTE for balancing\n",
      "---- CROSS-VALIDATION RESULTS ----\n",
      "{'accuracy': np.float64(0.9268),\n",
      " 'f1': np.float64(0.9268),\n",
      " 'precision': np.float64(0.927),\n",
      " 'r2_score': np.float64(0.8848),\n",
      " 'recall': np.float64(0.9268)}\n"
     ]
    }
   ],
   "source": [
    "cv_results, scores = model_pipeline(df, estimator, preprocessor, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the best model based on accuracy (or another metric)\n",
    "best_index = np.argmax(cv_results[\"test_accuracy\"])  # Using accuracy as the criterion\n",
    "# Retrieve the best model\n",
    "best_model = cv_results[\"estimator\"][best_index]\n",
    "\n",
    "save_model_weights(\"base_augmented\", best_model, \"histGradientBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tropical_cyclones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
