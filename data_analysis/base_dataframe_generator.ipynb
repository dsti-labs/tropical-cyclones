{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet of the base dataframe\n",
    "\n",
    "A Parquet file is a columnar storage file format optimized for use with big data processing frameworks, which efficiently compresses and encodes the data in a DataFrame for faster read and write operations.\n",
    "\n",
    "To transform into parquet we use :\n",
    "- pandas\n",
    "- pyarrow (as engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical => LabelBinarizer or OneHotEncoder or Label Encoder (one dimension with different values (1, 2, 3, 4, etc.))\n",
    "- SEASON (4)\n",
    "- BASIN (7)\n",
    "- NATURE (6)\n",
    "\n",
    "Numeric => everything between 0 and 1\n",
    "- LAT\n",
    "- LON\n",
    "- WIND \n",
    "- DIST2LAND\n",
    "- STORM_SPEED\n",
    "- STORM_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframe with a single header\n",
    "df = pd.read_parquet(\"../data/ibtracs_single_header.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on a copy of the dataset to preserve an untouched source of the dfcon\n",
    "df_ibtracs = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>SUBBASIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>BOM_GUST_PER</th>\n",
       "      <th>REUNION_GUST</th>\n",
       "      <th>REUNION_GUST_PER</th>\n",
       "      <th>USA_SEAHGT</th>\n",
       "      <th>USA_SEARAD_NE</th>\n",
       "      <th>USA_SEARAD_SE</th>\n",
       "      <th>USA_SEARAD_SW</th>\n",
       "      <th>USA_SEARAD_NW</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980001S13173</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>MM</td>\n",
       "      <td>PENI</td>\n",
       "      <td>1980-01-01 00:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>172.5</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980001S13173</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>MM</td>\n",
       "      <td>PENI</td>\n",
       "      <td>1980-01-01 03:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>172.4</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980001S13173</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>MM</td>\n",
       "      <td>PENI</td>\n",
       "      <td>1980-01-01 06:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>172.4</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980001S13173</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>MM</td>\n",
       "      <td>PENI</td>\n",
       "      <td>1980-01-01 09:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>172.4</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980001S13173</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>MM</td>\n",
       "      <td>PENI</td>\n",
       "      <td>1980-01-01 12:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>172.5</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SID  SEASON  NUMBER BASIN SUBBASIN  NAME             ISO_TIME  \\\n",
       "0  1980001S13173    1980       1    SP       MM  PENI  1980-01-01 00:00:00   \n",
       "1  1980001S13173    1980       1    SP       MM  PENI  1980-01-01 03:00:00   \n",
       "2  1980001S13173    1980       1    SP       MM  PENI  1980-01-01 06:00:00   \n",
       "3  1980001S13173    1980       1    SP       MM  PENI  1980-01-01 09:00:00   \n",
       "4  1980001S13173    1980       1    SP       MM  PENI  1980-01-01 12:00:00   \n",
       "\n",
       "  NATURE   LAT    LON  ... BOM_GUST_PER REUNION_GUST REUNION_GUST_PER  \\\n",
       "0     TS -12.5  172.5  ...                                              \n",
       "1     TS -12.2  172.4  ...                                              \n",
       "2     TS -11.9  172.4  ...                                              \n",
       "3     TS -11.7  172.4  ...                                              \n",
       "4     TS -11.5  172.5  ...                                              \n",
       "\n",
       "  USA_SEAHGT  USA_SEARAD_NE USA_SEARAD_SE USA_SEARAD_SW USA_SEARAD_NW  \\\n",
       "0                                                                       \n",
       "1                                                                       \n",
       "2                                                                       \n",
       "3                                                                       \n",
       "4                                                                       \n",
       "\n",
       "  STORM_SPEED STORM_DIR  \n",
       "0           6       350  \n",
       "1           6       350  \n",
       "2           5       360  \n",
       "3           4        10  \n",
       "4           4        20  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ibtracs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent downcasting in the .replace\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "for col in df_ibtracs.columns:\n",
    "    df_ibtracs[col] = df_ibtracs[col].replace(\" \", np.nan)\n",
    "    try:\n",
    "        df_ibtracs[col] = pd.to_numeric(df_ibtracs[col])\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibtracs = df_ibtracs.dropna(subset=[\"TD9636_STAGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibtracs[\"ISO_TIME\"] = pd.to_datetime(df_ibtracs[\"ISO_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date, latitude):\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "\n",
    "    if latitude >= 0:  # Northern Hemisphere\n",
    "        match month:\n",
    "            case 12 | 1 | 2:\n",
    "                return \"winter\"\n",
    "            case 3 | 4 | 5:\n",
    "                return \"spring\"\n",
    "            case 6 | 7 | 8:\n",
    "                return \"summer\"\n",
    "            case 9 | 10 | 11:\n",
    "                return \"fall\"\n",
    "\n",
    "    else:  # Southern Hemisphere\n",
    "        match month:\n",
    "            case 12 | 1 | 2:\n",
    "                return \"summer\"\n",
    "            case 3 | 4 | 5:\n",
    "                return \"fall\"\n",
    "            case 6 | 7 | 8:\n",
    "                return \"winter\"\n",
    "            case 9 | 10 | 11:\n",
    "                return \"spring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibtracs[\"SEASON\"] = df_ibtracs.apply(\n",
    "    lambda row: get_season(row[\"ISO_TIME\"], row[\"LAT\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming USA_WIND as WIND\n",
    "df_ibtracs.rename(columns={\"USA_WIND\": \"WIND\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibtracs[\n",
    "    [\"BOM_WIND\", \"WELLINGTON_WIND\", \"REUNION_WIND\", \"HKO_WIND\", \"TOKYO_WIND\"]\n",
    "] = (\n",
    "    df_ibtracs[\n",
    "        [\n",
    "            \"BOM_WIND\",\n",
    "            \"WELLINGTON_WIND\",\n",
    "            \"REUNION_WIND\",\n",
    "            \"HKO_WIND\",\n",
    "            \"TOKYO_WIND\",\n",
    "        ]\n",
    "    ]\n",
    "    * 1.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_list = [\n",
    "    \"TD9636_WIND\",\n",
    "    \"NEUMANN_WIND\",\n",
    "    \"HKO_WIND\",\n",
    "    \"TOKYO_WIND\",\n",
    "    \"BOM_WIND\",\n",
    "    \"WELLINGTON_WIND\",\n",
    "    \"REUNION_WIND\",\n",
    "    \"DS824_WIND\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if WIND is NaN we loop over the other columns to fill it\n",
    "for column in wind_list:\n",
    "    df_ibtracs[\"WIND\"] = df_ibtracs[\"WIND\"].fillna(value=df_ibtracs[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where WIND is still null\n",
    "df_ibtracs = df_ibtracs.dropna(subset=[\"WIND\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_ibtracs[\n",
    "    [\n",
    "        \"SEASON\",\n",
    "        \"BASIN\",\n",
    "        \"NATURE\",\n",
    "        \"LAT\",\n",
    "        \"LON\",\n",
    "        \"WIND\",\n",
    "        \"DIST2LAND\",\n",
    "        \"STORM_SPEED\",\n",
    "        \"STORM_DIR\",\n",
    "        \"TD9636_STAGE\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45025 entries, 0 to 67409\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SEASON        45025 non-null  object \n",
      " 1   BASIN         45025 non-null  object \n",
      " 2   NATURE        45025 non-null  object \n",
      " 3   LAT           45025 non-null  float64\n",
      " 4   LON           45025 non-null  float64\n",
      " 5   WIND          45025 non-null  float64\n",
      " 6   DIST2LAND     45025 non-null  int64  \n",
      " 7   STORM_SPEED   45025 non-null  float64\n",
      " 8   STORM_DIR     45025 non-null  float64\n",
      " 9   TD9636_STAGE  45025 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEASON          0\n",
       "BASIN           0\n",
       "NATURE          0\n",
       "LAT             0\n",
       "LON             0\n",
       "WIND            0\n",
       "DIST2LAND       0\n",
       "STORM_SPEED     0\n",
       "STORM_DIR       0\n",
       "TD9636_STAGE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DataFrame to parquet\n",
    "df_.to_parquet(\"../data/base.parquet\", engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tropical_cyclones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
